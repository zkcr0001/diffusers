{
 "cells": [
  {
   "cell_type": "code",
   "execution_count": 3,
   "id": "2890468d-a3ce-46a9-aa3a-4d2bfb5a9052",
   "metadata": {},
   "outputs": [
    {
     "ename": "ModuleNotFoundError",
     "evalue": "No module named 'stable_diffusion_controlnet_inpaint'",
     "output_type": "error",
     "traceback": [
      "\u001b[0;31m---------------------------------------------------------------------------\u001b[0m",
      "\u001b[0;31mModuleNotFoundError\u001b[0m                       Traceback (most recent call last)",
      "\u001b[0;32m<ipython-input-3-82c3fd381f9c>\u001b[0m in \u001b[0;36m<module>\u001b[0;34m\u001b[0m\n\u001b[1;32m      2\u001b[0m \u001b[0;32mimport\u001b[0m \u001b[0mtorch\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n\u001b[1;32m      3\u001b[0m \u001b[0;32mfrom\u001b[0m \u001b[0mPIL\u001b[0m \u001b[0;32mimport\u001b[0m \u001b[0mImage\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n\u001b[0;32m----> 4\u001b[0;31m \u001b[0;32mfrom\u001b[0m \u001b[0mstable_diffusion_controlnet_inpaint\u001b[0m \u001b[0;32mimport\u001b[0m \u001b[0mStableDiffusionControlNetInpaintPipeline\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n\u001b[0m\u001b[1;32m      5\u001b[0m \u001b[0;32mfrom\u001b[0m \u001b[0mtransformers\u001b[0m \u001b[0;32mimport\u001b[0m \u001b[0mAutoImageProcessor\u001b[0m\u001b[0;34m,\u001b[0m \u001b[0mUperNetForSemanticSegmentation\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n\u001b[1;32m      6\u001b[0m \u001b[0;32mfrom\u001b[0m \u001b[0mdiffusers\u001b[0m \u001b[0;32mimport\u001b[0m \u001b[0mControlNetModel\u001b[0m\u001b[0;34m,\u001b[0m \u001b[0mUniPCMultistepScheduler\u001b[0m\u001b[0;34m,\u001b[0m \u001b[0mLMSDiscreteScheduler\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n",
      "\u001b[0;31mModuleNotFoundError\u001b[0m: No module named 'stable_diffusion_controlnet_inpaint'"
     ]
    }
   ],
   "source": [
    "import numpy as np\n",
    "import torch\n",
    "from PIL import Image\n",
    "from stable_diffusion_controlnet_inpaint import StableDiffusionControlNetInpaintPipeline\n",
    "from transformers import AutoImageProcessor, UperNetForSemanticSegmentation\n",
    "from diffusers import ControlNetModel, UniPCMultistepScheduler, LMSDiscreteScheduler\n",
    "from diffusers.utils import load_image\n",
    "import matplotlib.pyplot as plt\n",
    "import cv2\n",
    "from torchvision import transforms\n",
    "from pathlib import Path\n",
    "import albumentations"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 2,
   "id": "0770044d-37b5-465f-a281-cad6203bb4f8",
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Collecting git+https://github.com/huggingface/diffusers\n",
      "  Cloning https://github.com/huggingface/diffusers to /tmp/pip-req-build-pcd0fk1h\n",
      "  Running command git clone -q https://github.com/huggingface/diffusers /tmp/pip-req-build-pcd0fk1h\n",
      "  Installing build dependencies ... \u001b[?25ldone\n",
      "\u001b[?25h  Getting requirements to build wheel ... \u001b[?25ldone\n",
      "\u001b[?25h    Preparing wheel metadata ... \u001b[?25ldone\n",
      "\u001b[?25hRequirement already satisfied (use --upgrade to upgrade): diffusers==0.15.0.dev0 from git+https://github.com/huggingface/diffusers in /home/ubuntu/.local/lib/python3.8/site-packages\n",
      "Requirement already satisfied: huggingface-hub>=0.13.2 in /home/ubuntu/.local/lib/python3.8/site-packages (from diffusers==0.15.0.dev0) (0.13.3)\n",
      "Requirement already satisfied: Pillow in /usr/lib/python3/dist-packages (from diffusers==0.15.0.dev0) (7.0.0)\n",
      "Requirement already satisfied: numpy in /home/ubuntu/.local/lib/python3.8/site-packages (from diffusers==0.15.0.dev0) (1.23.4)\n",
      "Requirement already satisfied: importlib-metadata in /home/ubuntu/.local/lib/python3.8/site-packages (from diffusers==0.15.0.dev0) (5.0.0)\n",
      "Requirement already satisfied: requests in /home/ubuntu/.local/lib/python3.8/site-packages (from diffusers==0.15.0.dev0) (2.28.1)\n",
      "Requirement already satisfied: regex!=2019.12.17 in /home/ubuntu/.local/lib/python3.8/site-packages (from diffusers==0.15.0.dev0) (2023.3.23)\n",
      "Requirement already satisfied: filelock in /usr/lib/python3/dist-packages (from diffusers==0.15.0.dev0) (3.0.12)\n",
      "Requirement already satisfied: pyyaml>=5.1 in /usr/lib/python3/dist-packages (from huggingface-hub>=0.13.2->diffusers==0.15.0.dev0) (5.3.1)\n",
      "Requirement already satisfied: typing-extensions>=3.7.4.3 in /home/ubuntu/.local/lib/python3.8/site-packages (from huggingface-hub>=0.13.2->diffusers==0.15.0.dev0) (4.4.0)\n",
      "Requirement already satisfied: packaging>=20.9 in /home/ubuntu/.local/lib/python3.8/site-packages (from huggingface-hub>=0.13.2->diffusers==0.15.0.dev0) (21.3)\n",
      "Requirement already satisfied: tqdm>=4.42.1 in /home/ubuntu/.local/lib/python3.8/site-packages (from huggingface-hub>=0.13.2->diffusers==0.15.0.dev0) (4.64.1)\n",
      "Requirement already satisfied: zipp>=0.5 in /usr/lib/python3/dist-packages (from importlib-metadata->diffusers==0.15.0.dev0) (1.0.0)\n",
      "Requirement already satisfied: idna<4,>=2.5 in /usr/lib/python3/dist-packages (from requests->diffusers==0.15.0.dev0) (2.8)\n",
      "Requirement already satisfied: certifi>=2017.4.17 in /usr/lib/python3/dist-packages (from requests->diffusers==0.15.0.dev0) (2019.11.28)\n",
      "Requirement already satisfied: charset-normalizer<3,>=2 in /home/ubuntu/.local/lib/python3.8/site-packages (from requests->diffusers==0.15.0.dev0) (2.1.1)\n",
      "Requirement already satisfied: urllib3<1.27,>=1.21.1 in /usr/lib/python3/dist-packages (from requests->diffusers==0.15.0.dev0) (1.25.8)\n",
      "Requirement already satisfied: pyparsing!=3.0.5,>=2.0.2 in /usr/lib/python3/dist-packages (from packaging>=20.9->huggingface-hub>=0.13.2->diffusers==0.15.0.dev0) (2.4.6)\n",
      "Building wheels for collected packages: diffusers\n",
      "  Building wheel for diffusers (PEP 517) ... \u001b[?25ldone\n",
      "\u001b[?25h  Created wheel for diffusers: filename=diffusers-0.15.0.dev0-py3-none-any.whl size=822542 sha256=b26e2b57f3fcadd4224cab3ed5e5fb47c4d9ce66bb94761af3954f7e5f74d5bc\n",
      "  Stored in directory: /tmp/pip-ephem-wheel-cache-ln8o1zhm/wheels/c6/77/b7/6d22ce35b79fbe5cc7513554d61c918bb4bf3eac5fdb8ae787\n",
      "Successfully built diffusers\n"
     ]
    }
   ],
   "source": [
    "!pip install git+https://github.com/huggingface/diffusers"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "d90713a7-3da0-47ad-8e5f-d3c4bb82bc76",
   "metadata": {},
   "source": [
    "# Canny"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "935cb8fb-32c7-489c-9c1d-55a3150db123",
   "metadata": {},
   "outputs": [],
   "source": [
    "image = load_image(\n",
    "        \"https://github.com/CompVis/latent-diffusion/raw/main/data/inpainting_examples/overture-creations-5sI6fQgYIuo.png\"\n",
    "    )\n",
    "mask_image = load_image(\n",
    "    \"https://github.com/CompVis/latent-diffusion/raw/main/data/inpainting_examples/overture-creations-5sI6fQgYIuo_mask.png\"\n",
    ")\n",
    "\n",
    "image = np.array(image)\n",
    "\n",
    "low_threshold = 100\n",
    "high_threshold = 200\n",
    "\n",
    "canny_image = cv2.Canny(image, low_threshold, high_threshold)\n",
    "canny_image = canny_image[:, :, None]\n",
    "canny_image = np.concatenate([canny_image, canny_image, canny_image], axis=2)\n",
    "canny_image = Image.fromarray(canny_image)\n",
    "\n",
    "controlnet = ControlNetModel.from_pretrained(\"lllyasviel/sd-controlnet-canny\",\n",
    "                                             torch_dtype=torch.float16\n",
    "                                            ).to(\"cuda\")\n",
    "pipe = StableDiffusionControlNetInpaintPipeline.from_pretrained(\n",
    "                \"runwayml/stable-diffusion-inpainting\", controlnet=controlnet, safety_checker=None,\n",
    "                torch_dtype=torch.float16\n",
    "            ).to(\"cuda\")\n",
    "pipe.scheduler = UniPCMultistepScheduler.from_config(pipe.scheduler.config)\n",
    "\n",
    "\n",
    "image_out = pipe(\n",
    "    \"Face of a yellow cat, high resolution, sitting on a park bench\",\n",
    "    image,\n",
    "    mask_image,\n",
    "    canny_image,\n",
    "    num_inference_steps=20,\n",
    ").images[0]"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "8b10c13c-7c27-4285-9dea-3ad8cdc4ec99",
   "metadata": {},
   "outputs": [],
   "source": [
    "SIZE = 512\n",
    "scale = 0.8\n",
    "image_rgba = Image.open(\n",
    "        \"/home/ubuntu/input_data_toy_boy_v2/0005_RGBA.png\"\n",
    "    )\n",
    "\n",
    "image_rgb = Image.fromarray(np.array(image_rgba)[:,:,:3])\n",
    "image_a = np.array(image_rgba)[:,:,3]\n",
    "print(np.min(image_a),np.max(image_a),np.unique(image_a))\n",
    "image_mask = 255 - image_a\n",
    "print(np.min(image_mask),np.max(image_mask),np.unique(image_mask))\n",
    "image_mask = Image.fromarray(np.repeat(image_mask[:,:,None], 3, axis = 2))\n",
    "new_size = int(SIZE * scale)\n",
    "\n",
    "image_transforms_resize = transforms.Compose(\n",
    "    [\n",
    "        transforms.Resize(new_size, interpolation=transforms.InterpolationMode.BILINEAR),\n",
    "        transforms.Pad(padding = (SIZE - new_size) // 2, fill= (255,255,255), padding_mode='constant'),\n",
    "    ]\n",
    ")\n",
    "\n",
    "mask_transforms_resize = transforms.Compose(\n",
    "    [\n",
    "        transforms.Resize(new_size, interpolation=transforms.InterpolationMode.BILINEAR),\n",
    "        transforms.Pad(padding = (SIZE - new_size) // 2, fill= (255, 255, 255), padding_mode='constant'),\n",
    "    ]\n",
    ")\n",
    "\n",
    "size_to_pad = (SIZE - new_size) // 2\n",
    "\n",
    "random_affine = albumentations.augmentations.geometric.transforms.Affine(translate_px = {\"x\": (-1 * size_to_pad, size_to_pad), \"y\": (-1 * size_to_pad, size_to_pad)})\n",
    "\n",
    "image_rgb = image_transforms_resize(image_rgb)\n",
    "image_mask = mask_transforms_resize(image_mask)\n",
    "\n",
    "result = random_affine(image = image_rgb, mask = image_mask)\n",
    "\n",
    "image_rgb = result['image']\n",
    "image_a = result['mask']\n",
    "\n",
    "image = image_rgb\n",
    "mask_image = image_mask\n",
    "\n",
    "image_np = np.array(image_rgb)\n",
    "\n",
    "low_threshold = 100\n",
    "high_threshold = 200\n",
    "\n",
    "canny_image = cv2.Canny(image_np, low_threshold, high_threshold)\n",
    "canny_image = canny_image[:, :, None]\n",
    "canny_image = np.concatenate([canny_image, canny_image, canny_image], axis=2)\n",
    "canny_image = Image.fromarray(canny_image)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "aedef883-955c-4fc0-8f8e-221a5d74c759",
   "metadata": {},
   "outputs": [],
   "source": [
    "save_to = Path(\"/home/ubuntu/0313_inpaint_results\")\n",
    "save_to.mkdir(exist_ok=True)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "b67c3a7e-68e1-4361-ab48-d44c4b33e3ea",
   "metadata": {},
   "outputs": [],
   "source": [
    "controlnet = ControlNetModel.from_pretrained(\"lllyasviel/sd-controlnet-canny\",\n",
    "                                             #torch_dtype=torch.float16\n",
    "                                            ).to(\"cuda\")\n",
    "pipe = StableDiffusionControlNetInpaintPipeline.from_pretrained(\n",
    "                \"runwayml/stable-diffusion-inpainting\", controlnet=controlnet, safety_checker=None,\n",
    "                #torch_dtype=torch.float16\n",
    "            ).to(\"cuda\")\n",
    "# pipe.scheduler = UniPCMultistepScheduler.from_config(pipe.scheduler.config)\n",
    "pipe.scheduler = LMSDiscreteScheduler.from_config(pipe.scheduler.config)\n",
    "\n",
    "torch.manual_seed(42)\n",
    "images = []\n",
    "for i in range(1):\n",
    "    image_out = pipe(\n",
    "        \"beautiful photo of a toy, sitting on a white table, birthday cake on the table, with colorful balloons on colorful wall, studio quality\",\n",
    "        image,\n",
    "        mask_image,\n",
    "        canny_image,\n",
    "        num_inference_steps=50,\n",
    "        negative_prompt = \"ugly, messy, blurry,low quality\"\n",
    "    ).images[0]\n",
    "    save_as = save_to / \"{:04n}.png\".format(i)\n",
    "    image_out.save(save_as)\n",
    "    if i < 8:\n",
    "        images.append(image_out)\n",
    "    \n",
    "images = Image.fromarray(np.concatenate(images,axis=1))\n",
    "save_as = save_to / \"{:04n}_concat.png\".format(i)\n",
    "images.save(save_as)\n",
    "plt.imshow(images)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 2,
   "id": "24079b87-4423-4b6f-b42f-1f9b5b4715c3",
   "metadata": {},
   "outputs": [
    {
     "ename": "NameError",
     "evalue": "name 'plt' is not defined",
     "output_type": "error",
     "traceback": [
      "\u001b[0;31m---------------------------------------------------------------------------\u001b[0m",
      "\u001b[0;31mNameError\u001b[0m                                 Traceback (most recent call last)",
      "\u001b[0;32m<ipython-input-2-ba3ab67a7a8e>\u001b[0m in \u001b[0;36m<module>\u001b[0;34m\u001b[0m\n\u001b[0;32m----> 1\u001b[0;31m fig, axs = plt.subplots(ncols=4, nrows=1, figsize=(15, 5),\n\u001b[0m\u001b[1;32m      2\u001b[0m                         layout=\"constrained\")\n\u001b[1;32m      3\u001b[0m \u001b[0;31m#axs[row, column]\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n\u001b[1;32m      4\u001b[0m \u001b[0maxs\u001b[0m\u001b[0;34m[\u001b[0m\u001b[0;36m0\u001b[0m\u001b[0;34m]\u001b[0m\u001b[0;34m.\u001b[0m\u001b[0mimshow\u001b[0m\u001b[0;34m(\u001b[0m\u001b[0mimage\u001b[0m\u001b[0;34m)\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n\u001b[1;32m      5\u001b[0m \u001b[0maxs\u001b[0m\u001b[0;34m[\u001b[0m\u001b[0;36m1\u001b[0m\u001b[0;34m]\u001b[0m\u001b[0;34m.\u001b[0m\u001b[0mimshow\u001b[0m\u001b[0;34m(\u001b[0m\u001b[0mmask_image\u001b[0m\u001b[0;34m)\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n",
      "\u001b[0;31mNameError\u001b[0m: name 'plt' is not defined"
     ]
    }
   ],
   "source": [
    "fig, axs = plt.subplots(ncols=4, nrows=1, figsize=(15, 5),\n",
    "                        layout=\"constrained\")\n",
    "#axs[row, column]\n",
    "axs[0].imshow(image)\n",
    "axs[1].imshow(mask_image)\n",
    "axs[2].imshow(canny_image)\n",
    "axs[3].imshow(image_out)\n",
    "fig.sav"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 3,
   "id": "f4fc9277-68d6-489e-a1b6-f99d96e400f4",
   "metadata": {},
   "outputs": [
    {
     "ename": "SyntaxError",
     "evalue": "unexpected EOF while parsing (<ipython-input-3-1b5b56e046d5>, line 2)",
     "output_type": "error",
     "traceback": [
      "\u001b[0;36m  File \u001b[0;32m\"<ipython-input-3-1b5b56e046d5>\"\u001b[0;36m, line \u001b[0;32m2\u001b[0m\n\u001b[0;31m    \u001b[0m\n\u001b[0m    ^\u001b[0m\n\u001b[0;31mSyntaxError\u001b[0m\u001b[0;31m:\u001b[0m unexpected EOF while parsing\n"
     ]
    }
   ],
   "source": [
    "def inpaint_with_controlnet(input_name, save_dir, prompt, num_images, n_prompt=\"\", num_inference_steps=50):\n",
    "    "
   ]
  },
  {
   "cell_type": "markdown",
   "id": "1bd6f6a5-f7bb-4ccb-a1fa-2f3d24113b54",
   "metadata": {},
   "source": [
    "# Segmentation"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 4,
   "id": "ac7cf10b-b479-443e-b50c-3c5162013c3a",
   "metadata": {},
   "outputs": [],
   "source": [
    "def ade_palette():\n",
    "    return [[120, 120, 120], [180, 120, 120], [6, 230, 230], [80, 50, 50],\n",
    "            [4, 200, 3], [120, 120, 80], [140, 140, 140], [204, 5, 255],\n",
    "            [230, 230, 230], [4, 250, 7], [224, 5, 255], [235, 255, 7],\n",
    "            [150, 5, 61], [120, 120, 70], [8, 255, 51], [255, 6, 82],\n",
    "            [143, 255, 140], [204, 255, 4], [255, 51, 7], [204, 70, 3],\n",
    "            [0, 102, 200], [61, 230, 250], [255, 6, 51], [11, 102, 255],\n",
    "            [255, 7, 71], [255, 9, 224], [9, 7, 230], [220, 220, 220],\n",
    "            [255, 9, 92], [112, 9, 255], [8, 255, 214], [7, 255, 224],\n",
    "            [255, 184, 6], [10, 255, 71], [255, 41, 10], [7, 255, 255],\n",
    "            [224, 255, 8], [102, 8, 255], [255, 61, 6], [255, 194, 7],\n",
    "            [255, 122, 8], [0, 255, 20], [255, 8, 41], [255, 5, 153],\n",
    "            [6, 51, 255], [235, 12, 255], [160, 150, 20], [0, 163, 255],\n",
    "            [140, 140, 140], [250, 10, 15], [20, 255, 0], [31, 255, 0],\n",
    "            [255, 31, 0], [255, 224, 0], [153, 255, 0], [0, 0, 255],\n",
    "            [255, 71, 0], [0, 235, 255], [0, 173, 255], [31, 0, 255],\n",
    "            [11, 200, 200], [255, 82, 0], [0, 255, 245], [0, 61, 255],\n",
    "            [0, 255, 112], [0, 255, 133], [255, 0, 0], [255, 163, 0],\n",
    "            [255, 102, 0], [194, 255, 0], [0, 143, 255], [51, 255, 0],\n",
    "            [0, 82, 255], [0, 255, 41], [0, 255, 173], [10, 0, 255],\n",
    "            [173, 255, 0], [0, 255, 153], [255, 92, 0], [255, 0, 255],\n",
    "            [255, 0, 245], [255, 0, 102], [255, 173, 0], [255, 0, 20],\n",
    "            [255, 184, 184], [0, 31, 255], [0, 255, 61], [0, 71, 255],\n",
    "            [255, 0, 204], [0, 255, 194], [0, 255, 82], [0, 10, 255],\n",
    "            [0, 112, 255], [51, 0, 255], [0, 194, 255], [0, 122, 255],\n",
    "            [0, 255, 163], [255, 153, 0], [0, 255, 10], [255, 112, 0],\n",
    "            [143, 255, 0], [82, 0, 255], [163, 255, 0], [255, 235, 0],\n",
    "            [8, 184, 170], [133, 0, 255], [0, 255, 92], [184, 0, 255],\n",
    "            [255, 0, 31], [0, 184, 255], [0, 214, 255], [255, 0, 112],\n",
    "            [92, 255, 0], [0, 224, 255], [112, 224, 255], [70, 184, 160],\n",
    "            [163, 0, 255], [153, 0, 255], [71, 255, 0], [255, 0, 163],\n",
    "            [255, 204, 0], [255, 0, 143], [0, 255, 235], [133, 255, 0],\n",
    "            [255, 0, 235], [245, 0, 255], [255, 0, 122], [255, 245, 0],\n",
    "            [10, 190, 212], [214, 255, 0], [0, 204, 255], [20, 0, 255],\n",
    "            [255, 255, 0], [0, 153, 255], [0, 41, 255], [0, 255, 204],\n",
    "            [41, 0, 255], [41, 255, 0], [173, 0, 255], [0, 245, 255],\n",
    "            [71, 0, 255], [122, 0, 255], [0, 255, 184], [0, 92, 255],\n",
    "            [184, 255, 0], [0, 133, 255], [255, 214, 0], [25, 194, 194],\n",
    "            [102, 255, 0], [92, 0, 255]]"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 5,
   "id": "4d106246-4231-4e8e-a87c-0c9278530ba5",
   "metadata": {},
   "outputs": [
    {
     "ename": "NameError",
     "evalue": "name 'AutoImageProcessor' is not defined",
     "output_type": "error",
     "traceback": [
      "\u001b[0;31m---------------------------------------------------------------------------\u001b[0m",
      "\u001b[0;31mNameError\u001b[0m                                 Traceback (most recent call last)",
      "\u001b[0;32m<ipython-input-5-8746b3e227c7>\u001b[0m in \u001b[0;36m<module>\u001b[0;34m\u001b[0m\n\u001b[0;32m----> 1\u001b[0;31m \u001b[0mimage_processor\u001b[0m \u001b[0;34m=\u001b[0m \u001b[0mAutoImageProcessor\u001b[0m\u001b[0;34m.\u001b[0m\u001b[0mfrom_pretrained\u001b[0m\u001b[0;34m(\u001b[0m\u001b[0;34m\"openmmlab/upernet-convnext-small\"\u001b[0m\u001b[0;34m)\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n\u001b[0m\u001b[1;32m      2\u001b[0m \u001b[0mimage_segmentor\u001b[0m \u001b[0;34m=\u001b[0m \u001b[0mUperNetForSemanticSegmentation\u001b[0m\u001b[0;34m.\u001b[0m\u001b[0mfrom_pretrained\u001b[0m\u001b[0;34m(\u001b[0m\u001b[0;34m\"openmmlab/upernet-convnext-small\"\u001b[0m\u001b[0;34m)\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n\u001b[1;32m      3\u001b[0m \u001b[0mcontrolnet\u001b[0m \u001b[0;34m=\u001b[0m \u001b[0mControlNetModel\u001b[0m\u001b[0;34m.\u001b[0m\u001b[0mfrom_pretrained\u001b[0m\u001b[0;34m(\u001b[0m\u001b[0;34m\"lllyasviel/sd-controlnet-seg\"\u001b[0m\u001b[0;34m,\u001b[0m \u001b[0mtorch_dtype\u001b[0m\u001b[0;34m=\u001b[0m\u001b[0mtorch\u001b[0m\u001b[0;34m.\u001b[0m\u001b[0mfloat16\u001b[0m\u001b[0;34m)\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n\u001b[1;32m      4\u001b[0m pipe = StableDiffusionControlNetInpaintPipeline.from_pretrained(\n\u001b[1;32m      5\u001b[0m                 \u001b[0;34m\"runwayml/stable-diffusion-inpainting\"\u001b[0m\u001b[0;34m,\u001b[0m \u001b[0mcontrolnet\u001b[0m\u001b[0;34m=\u001b[0m\u001b[0mcontrolnet\u001b[0m\u001b[0;34m,\u001b[0m \u001b[0msafety_checker\u001b[0m\u001b[0;34m=\u001b[0m\u001b[0;32mNone\u001b[0m\u001b[0;34m,\u001b[0m \u001b[0mtorch_dtype\u001b[0m\u001b[0;34m=\u001b[0m\u001b[0mtorch\u001b[0m\u001b[0;34m.\u001b[0m\u001b[0mfloat16\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n",
      "\u001b[0;31mNameError\u001b[0m: name 'AutoImageProcessor' is not defined"
     ]
    }
   ],
   "source": [
    "image_processor = AutoImageProcessor.from_pretrained(\"openmmlab/upernet-convnext-small\")\n",
    "image_segmentor = UperNetForSemanticSegmentation.from_pretrained(\"openmmlab/upernet-convnext-small\")\n",
    "controlnet = ControlNetModel.from_pretrained(\"lllyasviel/sd-controlnet-seg\", torch_dtype=torch.float16)\n",
    "pipe = StableDiffusionControlNetInpaintPipeline.from_pretrained(\n",
    "                \"runwayml/stable-diffusion-inpainting\", controlnet=controlnet, safety_checker=None, torch_dtype=torch.float16\n",
    "            )\n"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 6,
   "id": "1506a804-7c7f-4d2d-93b2-0060313a3342",
   "metadata": {},
   "outputs": [
    {
     "ename": "NameError",
     "evalue": "name 'UniPCMultistepScheduler' is not defined",
     "output_type": "error",
     "traceback": [
      "\u001b[0;31m---------------------------------------------------------------------------\u001b[0m",
      "\u001b[0;31mNameError\u001b[0m                                 Traceback (most recent call last)",
      "\u001b[0;32m<ipython-input-6-371be3281b79>\u001b[0m in \u001b[0;36m<module>\u001b[0;34m\u001b[0m\n\u001b[0;32m----> 1\u001b[0;31m \u001b[0mpipe\u001b[0m\u001b[0;34m.\u001b[0m\u001b[0mscheduler\u001b[0m \u001b[0;34m=\u001b[0m \u001b[0mUniPCMultistepScheduler\u001b[0m\u001b[0;34m.\u001b[0m\u001b[0mfrom_config\u001b[0m\u001b[0;34m(\u001b[0m\u001b[0mpipe\u001b[0m\u001b[0;34m.\u001b[0m\u001b[0mscheduler\u001b[0m\u001b[0;34m.\u001b[0m\u001b[0mconfig\u001b[0m\u001b[0;34m)\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n\u001b[0m\u001b[1;32m      2\u001b[0m \u001b[0;31m# pipe.enable_xformers_memory_efficient_attention()\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n\u001b[1;32m      3\u001b[0m \u001b[0mpipe\u001b[0m\u001b[0;34m.\u001b[0m\u001b[0menable_model_cpu_offload\u001b[0m\u001b[0;34m(\u001b[0m\u001b[0;34m)\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n",
      "\u001b[0;31mNameError\u001b[0m: name 'UniPCMultistepScheduler' is not defined"
     ]
    }
   ],
   "source": [
    "pipe.scheduler = UniPCMultistepScheduler.from_config(pipe.scheduler.config)\n",
    "# pipe.enable_xformers_memory_efficient_attention()\n",
    "pipe.enable_model_cpu_offload()"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 7,
   "id": "d0578633-0bb9-456d-b823-d756deb64775",
   "metadata": {},
   "outputs": [],
   "source": [
    "def image_to_seg(image):\n",
    "    pixel_values = image_processor(image, return_tensors=\"pt\").pixel_values\n",
    "    with torch.no_grad():\n",
    "        outputs = image_segmentor(pixel_values)\n",
    "    seg = image_processor.post_process_semantic_segmentation(outputs, target_sizes=[image.size[::-1]])[0]\n",
    "    color_seg = np.zeros((seg.shape[0], seg.shape[1], 3), dtype=np.uint8)  # height, width, 3\n",
    "    palette = np.array(ade_palette())\n",
    "    for label, color in enumerate(palette):\n",
    "        color_seg[seg == label, :] = color\n",
    "    color_seg = color_seg.astype(np.uint8)\n",
    "    seg_image = Image.fromarray(color_seg)\n",
    "    return seg_image"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 8,
   "id": "5e69b908-66fd-48a2-a2b4-1338c652f1eb",
   "metadata": {},
   "outputs": [
    {
     "ename": "NameError",
     "evalue": "name 'load_image' is not defined",
     "output_type": "error",
     "traceback": [
      "\u001b[0;31m---------------------------------------------------------------------------\u001b[0m",
      "\u001b[0;31mNameError\u001b[0m                                 Traceback (most recent call last)",
      "\u001b[0;32m<ipython-input-8-ae843be7f579>\u001b[0m in \u001b[0;36m<module>\u001b[0;34m\u001b[0m\n\u001b[0;32m----> 1\u001b[0;31m image = load_image(\n\u001b[0m\u001b[1;32m      2\u001b[0m         \u001b[0;34m\"https://github.com/CompVis/latent-diffusion/raw/main/data/inpainting_examples/overture-creations-5sI6fQgYIuo.png\"\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n\u001b[1;32m      3\u001b[0m     )\n\u001b[1;32m      4\u001b[0m mask_image = load_image(\n\u001b[1;32m      5\u001b[0m     \u001b[0;34m\"https://github.com/CompVis/latent-diffusion/raw/main/data/inpainting_examples/overture-creations-5sI6fQgYIuo_mask.png\"\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n",
      "\u001b[0;31mNameError\u001b[0m: name 'load_image' is not defined"
     ]
    }
   ],
   "source": [
    "image = load_image(\n",
    "        \"https://github.com/CompVis/latent-diffusion/raw/main/data/inpainting_examples/overture-creations-5sI6fQgYIuo.png\"\n",
    "    )\n",
    "mask_image = load_image(\n",
    "    \"https://github.com/CompVis/latent-diffusion/raw/main/data/inpainting_examples/overture-creations-5sI6fQgYIuo_mask.png\"\n",
    ")\n",
    "\n",
    "controlnet_conditioning_image = image_to_seg(image)\n",
    "\n",
    "image_out = pipe(\n",
    "    \"Face of a yellow cat, high resolution, sitting on a park bench\",\n",
    "    image,\n",
    "    mask_image,\n",
    "    controlnet_conditioning_image,\n",
    "    num_inference_steps=20,\n",
    ").images[0]\n",
    "\n",
    "# image.save(\"out.png\")"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 9,
   "id": "1fe36510-14cb-49b1-bf97-a4db877c89b8",
   "metadata": {},
   "outputs": [
    {
     "ename": "NameError",
     "evalue": "name 'plt' is not defined",
     "output_type": "error",
     "traceback": [
      "\u001b[0;31m---------------------------------------------------------------------------\u001b[0m",
      "\u001b[0;31mNameError\u001b[0m                                 Traceback (most recent call last)",
      "\u001b[0;32m<ipython-input-9-35c70d7f3432>\u001b[0m in \u001b[0;36m<module>\u001b[0;34m\u001b[0m\n\u001b[0;32m----> 1\u001b[0;31m fig, axs = plt.subplots(ncols=4, nrows=1, figsize=(5.5, 3.5),\n\u001b[0m\u001b[1;32m      2\u001b[0m                         layout=\"constrained\")\n\u001b[1;32m      3\u001b[0m \u001b[0;31m#axs[row, column]\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n\u001b[1;32m      4\u001b[0m \u001b[0maxs\u001b[0m\u001b[0;34m[\u001b[0m\u001b[0;36m0\u001b[0m\u001b[0;34m]\u001b[0m\u001b[0;34m.\u001b[0m\u001b[0mimshow\u001b[0m\u001b[0;34m(\u001b[0m\u001b[0mimage\u001b[0m\u001b[0;34m)\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n\u001b[1;32m      5\u001b[0m \u001b[0maxs\u001b[0m\u001b[0;34m[\u001b[0m\u001b[0;36m1\u001b[0m\u001b[0;34m]\u001b[0m\u001b[0;34m.\u001b[0m\u001b[0mimshow\u001b[0m\u001b[0;34m(\u001b[0m\u001b[0mmask_image\u001b[0m\u001b[0;34m)\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n",
      "\u001b[0;31mNameError\u001b[0m: name 'plt' is not defined"
     ]
    }
   ],
   "source": [
    "fig, axs = plt.subplots(ncols=4, nrows=1, figsize=(5.5, 3.5),\n",
    "                        layout=\"constrained\")\n",
    "#axs[row, column]\n",
    "axs[0].imshow(image)\n",
    "axs[1].imshow(mask_image)\n",
    "axs[2].imshow(controlnet_conditioning_image)\n",
    "axs[3].imshow(image_out)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 10,
   "id": "7ced4609-7e83-4300-a8d4-080a83fb4abb",
   "metadata": {},
   "outputs": [
    {
     "ename": "NameError",
     "evalue": "name 'mask_image' is not defined",
     "output_type": "error",
     "traceback": [
      "\u001b[0;31m---------------------------------------------------------------------------\u001b[0m",
      "\u001b[0;31mNameError\u001b[0m                                 Traceback (most recent call last)",
      "\u001b[0;32m<ipython-input-10-3c5155cba254>\u001b[0m in \u001b[0;36m<module>\u001b[0;34m\u001b[0m\n\u001b[0;32m----> 1\u001b[0;31m \u001b[0mprint\u001b[0m\u001b[0;34m(\u001b[0m\u001b[0mnp\u001b[0m\u001b[0;34m.\u001b[0m\u001b[0mmax\u001b[0m\u001b[0;34m(\u001b[0m\u001b[0mnp\u001b[0m\u001b[0;34m.\u001b[0m\u001b[0marray\u001b[0m\u001b[0;34m(\u001b[0m\u001b[0mmask_image\u001b[0m\u001b[0;34m)\u001b[0m\u001b[0;34m)\u001b[0m\u001b[0;34m,\u001b[0m\u001b[0mnp\u001b[0m\u001b[0;34m.\u001b[0m\u001b[0mmin\u001b[0m\u001b[0;34m(\u001b[0m\u001b[0mnp\u001b[0m\u001b[0;34m.\u001b[0m\u001b[0marray\u001b[0m\u001b[0;34m(\u001b[0m\u001b[0mmask_image\u001b[0m\u001b[0;34m)\u001b[0m\u001b[0;34m)\u001b[0m\u001b[0;34m)\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n\u001b[0m\u001b[1;32m      2\u001b[0m \u001b[0mprint\u001b[0m\u001b[0;34m(\u001b[0m\u001b[0mnp\u001b[0m\u001b[0;34m.\u001b[0m\u001b[0munique\u001b[0m\u001b[0;34m(\u001b[0m\u001b[0mnp\u001b[0m\u001b[0;34m.\u001b[0m\u001b[0marray\u001b[0m\u001b[0;34m(\u001b[0m\u001b[0mmask_image\u001b[0m\u001b[0;34m)\u001b[0m\u001b[0;34m)\u001b[0m\u001b[0;34m)\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n",
      "\u001b[0;31mNameError\u001b[0m: name 'mask_image' is not defined"
     ]
    }
   ],
   "source": [
    "print(np.max(np.array(mask_image)),np.min(np.array(mask_image)))\n",
    "print(np.unique(np.array(mask_image)))"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "e6432e14-dabd-48e1-a7f4-7eaa8213d2b4",
   "metadata": {},
   "outputs": [],
   "source": []
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "f6968256-f1a7-401c-b91f-c95e06faddd1",
   "metadata": {},
   "outputs": [],
   "source": []
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "bb1a322c-956c-457c-a735-49129a564417",
   "metadata": {},
   "outputs": [],
   "source": []
  }
 ],
 "metadata": {
  "kernelspec": {
   "display_name": "Python 3",
   "language": "python",
   "name": "python3"
  },
  "language_info": {
   "codemirror_mode": {
    "name": "ipython",
    "version": 3
   },
   "file_extension": ".py",
   "mimetype": "text/x-python",
   "name": "python",
   "nbconvert_exporter": "python",
   "pygments_lexer": "ipython3",
   "version": "3.8.10"
  }
 },
 "nbformat": 4,
 "nbformat_minor": 5
}
